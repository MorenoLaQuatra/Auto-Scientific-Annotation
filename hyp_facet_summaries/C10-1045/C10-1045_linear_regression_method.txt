Fourth, we show how to build better models for three different parsers. Finally, we show that in application settings, the absence of gold segmentation lowers parsing performance by 2–5% F1. Crucially, the conventional orthographic form of MSA text is unvocalized, a property that results in a deficient graphical representation. To facilitate comparison with previous work, we exhaustively evaluate this grammar and two other parsing models when gold segmentation is assumed (§5). Finally, we provide a realistic eval uation in which segmentation is performed both in a pipeline and jointly with parsing (§6). with the number of exactly matching guess trees. 6 Joint Segmentation and Parsing. The ATB segmentation scheme is one of many alternatives. But gold segmentation is not available in application settings, so a segmenter and parser are arranged in a pipeline. Segmentation errors cascade into the parsing phase, placing an artificial limit on parsing performance. Despite their simplicity, uni- gram weights have been shown as an effective feature in segmentation models (Dyer, 2009).13 The joint parser/segmenter is compared to a pipeline that uses MADA (v3.0), a state-of-the-art Arabic segmenter, configured to replicate ATB segmentation (Habash and Rambow, 2005). input token, the segmentation is then performed deterministically given the 1-best analysis. Table 9 shows that MADA produces a high quality segmentation, and that the effect of cascading segmentation errors on parsing is only 1.92% F1. In these experiments, the input lacks segmentation markers, hence the slightly different dev set baseline than in Table 6. Parent