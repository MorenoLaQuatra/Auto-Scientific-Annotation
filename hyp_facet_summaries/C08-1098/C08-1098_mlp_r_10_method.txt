The best results are obtained with a context size of 10. Our tagger was used with a context size of 10. These values were optimal on the development data. The accuracy of our tagger is lower than on the development data. This could be due to the higher rate of unknown words (10.0% vs. 7.7%). The resulting score of a binomial test is below 0.001. Our tagger is quite fast, although not as fast as the TnT tagger. The training with a context size of 10 took about 4 minutes. (2003) describe a more complex backoff smoothing method. These two-class trees can be pruned with a fixed pruning threshold. The best accuracy of the TnT tagger was 88.2% with a maximal suffix length of 5. The corresponding figures for the test data are. 89.53% for our tagger and 88.88% for the TnT tag- ger. The difference is significant. The tagging accuracy reported by Kempe was below that of a traditional trigram tagger. Schmid (1994) and Ma`rquez (1999) used decision trees for the estimation of contextual tag probabilities, but without a decomposition of the tag probability. used. Morcˇe’s tagging accuracy was 95.12%, 0.3% better than the n-gram tagger. 1 7