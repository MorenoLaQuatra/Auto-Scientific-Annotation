Named Entity Recognition: A Maximum Entropy Approach Using Global Information We propose maximizing , where is the sequence of named- entity tags assigned to the words in the sentence , and is the information that can be extracted from the whole document containing . Our system is built on a maximum entropy classifier. Mikheev et al. In addition, each feature function is a binary function. This is an iterative method that improves the estimation of the parameters at each iteration. This might be because our features are more comprehensive than those used by Borthwick. 4.1 Local Features. The zone to which a token belongs is used as a feature. A token that is allCaps will also be initCaps. If is not initCaps, then (not-initCaps, ) is set to 1. Note that we check for , the word preceding the consecutive sequence of initCaps tokens, since person prefixes like Mr., Dr., etc are not part of person names, whereas corporate suffixes like Corp., Inc., etc are part of corporate names. For a word whose initCaps might be due to its position rather than its meaning (in headlines, first word of a sentence, etc), the case information of other occurrences might be more accurate than its own. Acronyms (ACRO): Words made up of all capitalized letters in the text zone will be stored as acronyms (e.g., IBM). For every sequence of initial capitalized words, its longest substring that occurs in the same document as a sequence of initCaps is identified. needs to be in initCaps to be considered for this feature. If is unique, then a feature (Unique, Zone) is set to 1, where Zone is the document zone where appears. Mikheev et al. ‚Äù).